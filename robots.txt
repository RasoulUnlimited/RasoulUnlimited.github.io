# robots.txt for https://rasoulunlimited.ir
# Maintainer: Mohammad Rasoul Sohrabi (Rasoul Unlimited)
# Hosting: GitHub Pages (proxied via Cloudflare)
# Contact: rasoul.unlimited@gmail.com
# Updated: 2025-11-23 (SEO Crawlability Fix)

Sitemap: https://rasoulunlimited.ir/sitemap.xml
Host: rasoulunlimited.ir

# =====================================================================
# General Crawling Policy
# =====================================================================
User-agent: *
# By default, all public content is allowed unless explicitly disallowed.
Allow: /

# =====================================================================
# CRITICAL: Block non-public sections (kept minimal to allow navigation/schema crawl)
# =====================================================================
# System files and build artifacts
Disallow: /node_modules/

# =====================================================================
# High-value Public Sections (navigation / concepts / docs)
# (These are already covered by "Allow: /" â€“ listed here for clarity.)
# =====================================================================
# Language roots
#   - /                : Persian (default)
#   - /en/             : English section
#   - /projects/       : Project index and subpages
#   - /faq/            : Frequently Asked Questions
#   - /wiki/           : Extended background
#   - /concepts/       : Strategic concepts (visual-identity-loop, etc)
#
# Core pages
#   - /about.html
#   - /resume.html, /en/resume.html
#   - /press.html, /en/press.html
#   - /media.html
#   - /proof.html
#   - /security.html
#   - /contact.html
#   - /ai/
#
# Press kit and assets
#   - /press-kit/, /press-kit/fa/
#   - /assets/css/
#   - /assets/images/
#   - /assets/js/
#   - /assets/vendor/
#
# Semantic / human-readable identity
#   - /humans.txt
#   - /links.txt

# =====================================================================
# Blocked Paths (non-public, internal, or build-related)
# =====================================================================
# Generic admin / auth endpoints (not intended for indexing)
Disallow: /admin/
Disallow: /login/
Disallow: /register/

# Server-side or legacy script locations
Disallow: /cgi-bin/

# Internal storage / non-public areas
Disallow: /private/
Disallow: /tmp/
Disallow: /backup/
Disallow: /cloudflare/
Disallow: /UnlimitedWeb/

# Build / repository meta files that may be present in the root
Disallow: /gulpfile.js
Disallow: /package.json
Disallow: /package-lock.json
Disallow: /README.md
Disallow: /LICENSE

# =====================================================================
# Security-sensitive and Machine-readable Assets (SEO Optimization)
# =====================================================================
# Security key storage (non-user-facing)
Disallow: /assets/keys/

# Machine-readable semantic data (JSON-LD schemas)
# Note: Search engines can still crawl schema.org data from HTML; 
# this prevents crawling the directory as a separate section
# Disallow: /schema/

# Security metadata files (system-level, not user-facing)
Disallow: /.well-known/security.txt

# =====================================================================
# Notes (Updated Nov 23 2025)
# =====================================================================
# - Navigation fragments (/includes) and structured data (/schema) are now crawlable
#   so search engines can see internal links and JSON-LD. Use X-Robots-Tag headers
#   for noindex on machine-only files if needed.
# - Custom 404s are crawlable; meta robots handles noindex.
# - High-value sections rely on the global "Allow: /" directive; sensitive areas stay disallowed.
